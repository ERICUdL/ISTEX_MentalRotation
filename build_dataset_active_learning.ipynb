{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, pickle, argparse, json, os\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ids(json_file):\n",
    "    # takes a json file with list of articles meta data including a field named 'istex_id'\n",
    "    # retuns numpy array with the istex_id of the articles\n",
    "    ids = np.arange(len(json_file), dtype=np.object)\n",
    "    for (i,s) in enumerate(json_file):\n",
    "        ids[i] = s['istex_id']\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_results(filename):\n",
    "    results = pd.read_csv(filename, sep=';', index_col=0)\n",
    "    sampled_results = results[results['PF'] != '  ']\n",
    "    sampled_results['P'] = np.array(sampled_results['PF'], dtype=np.float)\n",
    "    sampled_results['R'] = np.array(sampled_results['RM'], dtype=np.float)\n",
    "    sampled_results['Score'] = (sampled_results['P'] + sampled_results['R'] )/ 2.0\n",
    "    return sampled_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4174940, 150)\n"
     ]
    }
   ],
   "source": [
    "svd = pickle.load(open('../RecSys_Exp_files/182_381_vec150_results//output_svd.pickle','rb'))\n",
    "print svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCBL_ANNOTATED001MENTAL000ROTATION10100000001\n",
      "UCBL_ANNOTATED001MENTAL000ROTATION10100000162\n",
      "MRISTEX_FDF8A158137E00C72623548DD41D074D8AAC1725\n",
      "MRISTEX_00211AA25963CDCD086A6B844C42F42645FAD50A\n",
      "ISTEX_C3D2F8606E1497B25D26FE4DE92BD00608EED309\n",
      "ISTEX_17E8AB6E71469134AE441F9733B45166E4062ACF\n",
      "4174940\n"
     ]
    }
   ],
   "source": [
    "index = json.load(open('../RecSys_Exp_files/182_381_vec150_results/output_paragraph_index.json','rb'))\n",
    "\n",
    "print index['0']\n",
    "print index['181']\n",
    "print index['182']\n",
    "print index['380']\n",
    "print index['381']\n",
    "print index['111182']\n",
    "print len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNOTATED001MENTAL000ROTATION10100000001\n",
      "ANNOTATED001MENTAL000ROTATION10100000162\n",
      "FDF8A158137E00C72623548DD41D074D8AAC1725\n",
      "00211AA25963CDCD086A6B844C42F42645FAD50A\n",
      "C3D2F8606E1497B25D26FE4DE92BD00608EED309\n",
      "17E8AB6E71469134AE441F9733B45166E4062ACF\n",
      "4174940\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in index.items():\n",
    "    index[k] = v.split('_')[1]\n",
    "\n",
    "print index['0']\n",
    "print index['181']\n",
    "print index['182']\n",
    "print index['380']\n",
    "print index['381']\n",
    "print index['111182']\n",
    "print len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_index = json.load(open('../RecSys_Exp_files/182_381_vec150_results/output_paragraph_inversed_index.json','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original inversed_index\n",
      "[(u'ISTEX_D89FA3AC3521074D46F4245762153DF497BFFA1F', 2002320), (u'ISTEX_18EAF4D6A126B077EB38667801D1B7292F32FF49', 2483732), (u'ISTEX_5F91044435FCC4FABB9F02E31467DCFE75F4A7BE', 1429049), (u'ISTEX_EBB03C272511D346B3D68CA10EBD929CE7A31DB8', 128349), (u'ISTEX_5776E10BEF3FF14794D60A604B2CA12B1695894B', 1225023)]\n",
      "processed inversed_index\n",
      "[(u'FCF1393F9B8136AC08FB67E88F94F3CF62C17288', 3517138), (u'482E1102A1114327A744FD2ADB4D9F8FF7E9A70B', 751643), (u'A81022B6295AE66F68A10222C3B94A06B033C1BA', 3983232), (u'F27F00C86A2994208F0143A5CD2217AB87B21A64', 1906438), (u'939B5153F5A4B8053FFAF8E7BCE062B341DB9BEB', 3603049)]\n"
     ]
    }
   ],
   "source": [
    "print 'original inversed_index'\n",
    "print inv_index.items()[:5]\n",
    "inversed_index = dict()\n",
    "for (k, v) in inv_index.items():\n",
    "    key = k.split('_')[1]\n",
    "    inversed_index[key] = v\n",
    "print 'processed inversed_index'\n",
    "print inversed_index.items()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id lenght must be: 40\n",
      "exceptions if any:\n"
     ]
    }
   ],
   "source": [
    "#double-check index values by length\n",
    "print 'id lenght must be:', len(index['182'])\n",
    "print \"exceptions if any:\"\n",
    "for (k, v) in index.items():\n",
    "    if len(v) < 40:\n",
    "        print (k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = json.load(open('../RecSys_Exp_files/ISTEX_MentalRotation/sample_data/sportArticlesAsIstex_UniqID_182.json','r'))\n",
    "test = json.load(open('../RecSys_Exp_files/ISTEX_MentalRotation/sample_data/MentalRotationInMetaDataIstexWithoutAnnotated.json','r'))\n",
    "seed_ids = get_ids(seed)\n",
    "test_ids = get_ids(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNOTATED001MENTAL000ROTATION10100000001\n",
      "FDF8A158137E00C72623548DD41D074D8AAC1725\n"
     ]
    }
   ],
   "source": [
    "print seed_ids[0]\n",
    "print test_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "results = read_results('annotations/SSbE.csv')\n",
    "# considering that the good result is the one that at least one of the experts marked as relevant\n",
    "#  while the other could not decide\n",
    "good_results = results[results['Score'] > 0.5][\"Articles\"].values\n",
    "# considering that the bad result is the one that at least one of the experts marked as irrelevant\n",
    "bad_results = results[results['Score'] < 0.5][\"Articles\"].values\n",
    "# Results with disagreement between the 2 experts or both cannot_decide were excluded (0.5 values)\n",
    "excluded_results = results[results['Score'] == 0.5][\"Articles\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ids_from_link(results):\n",
    "    # takes a numpy array of url_link values\n",
    "    # retuns numpy array with the istex_id of the articles\n",
    "    result_ids = np.arange(results.shape[0], dtype=np.object)\n",
    "    for (i,r) in enumerate(results):\n",
    "        splt = r.split('/')\n",
    "        result_ids[i] = splt[4]\n",
    "    return result_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_ids = get_ids_from_link(good_results)\n",
    "bad_ids = get_ids_from_link(bad_results)\n",
    "excluded_ids = get_ids_from_link(excluded_results)\n",
    "print len(good_ids)\n",
    "len(excluded_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for doc_id in good_ids:\n",
    "    if len(doc_id) != 40:\n",
    "        print doc_id\n",
    "\n",
    "for doc_id in seed_ids:\n",
    "    if len(doc_id) != 40:\n",
    "        print doc_id\n",
    "        \n",
    "for doc_id in test_ids:\n",
    "    if len(doc_id) != 40:\n",
    "        print doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 7, 19, 5, 16, 6, 14, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[327183, 1684624, 3904508, 3821319, 1108301]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print random.sample(range(20), 10)\n",
    "indecies = np.random.choice(range(4174940),size=5)\n",
    "indecies.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def balanced_activelearn_ids_dataset(pos_arr, neg_arr, others_arr, size):\n",
    "    pos_size = size/2\n",
    "    neg_size = (size - pos_size) - len(neg_arr) # in case of odd int value of size\n",
    "    positives = sampling(pos_arr, 'positive', pos_size)\n",
    "    negatives_sure = sampling(neg_arr, 'negative', len(neg_arr))\n",
    "    negatives_rand = sampling(others_arr, 'negative', neg_size)\n",
    "    res = np.hstack((positives, negatives_sure))\n",
    "    return np.hstack((res, negatives_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of negatives: 70\n",
      "size of positives: 402\n"
     ]
    }
   ],
   "source": [
    "negative_ids = bad_ids\n",
    "negative_ids_lst = negative_ids.tolist()\n",
    "positive_ids_1= np.hstack((good_ids, seed_ids))\n",
    "positive_ids = np.hstack((positive_ids_1, test_ids))\n",
    "positive_ids_lst = positive_ids.tolist()\n",
    "print 'size of negatives:', len(negative_ids_lst)\n",
    "print 'size of positives:', len(positive_ids_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'B4B4F0628AFF81062EB596FFC0DD6A637F27737E'\n",
      " u'A5F0E06E96CB5ECC5E3C7A376F9A006C2B21EDCC'\n",
      " u'E1F652D41E8E824FAC586C990F03033637F5871E'\n",
      " u'89EF426699BD2C1085F4B1BFD80CCE098301EED4'\n",
      " u'078EB70E4B0CF7579CEA897DAA7B9E834A988103'\n",
      " u'2E15B0334C74F74F2F129D2A8B1264BFF1C2C658'\n",
      " u'B4BCF54DB5ECD8392CD6D07E62A60931AB27DC30'\n",
      " u'D4D87F6F661A02E2041D2414AE520547A3B23200'\n",
      " u'36F76E60FFDB3860F06EB0B379552F74BE639CF4'\n",
      " u'D25A0773984B9E38EBBEE50D006738FB61A2A857']\n"
     ]
    }
   ],
   "source": [
    "all_ids = np.hstack((negative_ids_lst, positive_ids_lst))\n",
    "all_ids_lst = all_ids.tolist()\n",
    "others_size = len(index.keys()) - len(all_ids_lst)\n",
    "\n",
    "other_ids = np.arange(others_size-181, dtype=np.object)#This extra 181 are a bug that need debugging\n",
    "i = 0\n",
    "for (k, v) in index.items():\n",
    "    if v in all_ids_lst:\n",
    "        continue\n",
    "    else: \n",
    "        other_ids[i] = v\n",
    "        i += 1\n",
    "print other_ids[-10:]\n",
    "other_ids_lst = other_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_svd_from_doc_id(ids_lst):\n",
    "    res = np.arange(len(ids_lst), dtype=np.object)\n",
    "    i = 0\n",
    "    for (i, idd) in enumerate(ids_lst):\n",
    "        res[i] = svd[int(inversed_index[idd])]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_docs_svd = get_svd_from_doc_id(positive_ids_lst)\n",
    "negative_docs_svd = get_svd_from_doc_id(negative_ids_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We have an issue using this function...\n",
    "#dataset_ids = balanced_activelearn_ids_dataset(positive_ids, negative_ids, others, 750)\n",
    "#dataset_ids[-306:]\n",
    "#len(dataset_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_of_positives 402\n",
      "size_of_negatives 70\n",
      "needed size of negative random sampled documents: 332\n",
      "size of generated negative_rand_docs_svd: 332\n"
     ]
    }
   ],
   "source": [
    "#generate some randome negative examples to have a balanced dataset for training\n",
    "size_of_positives = len(positive_docs_svd)\n",
    "print 'size_of_positives', size_of_positives\n",
    "size_of_negatives = len(negative_docs_svd)\n",
    "print 'size_of_negatives', size_of_negatives\n",
    "neg_random_size = size_of_positives - size_of_negatives\n",
    "print 'needed size of negative random sampled documents:', neg_random_size\n",
    "indicies = random.sample(range(len(index)), neg_random_size)\n",
    "neg_random = other_ids[indicies]\n",
    "neg_random_lst = neg_random.tolist()\n",
    "negative_rand_docs_svd = get_svd_from_doc_id(neg_random_lst)\n",
    "print 'size of generated negative_rand_docs_svd:', len(negative_rand_docs_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Now we have 384 positive examples and 70+314 negative examples, use these for training the classifier \n",
    "and finally use that classifier to get topn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_docs_svd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(positive_docs_svd, negative_docs_svd, negative_rand_docs_svd):\n",
    "\n",
    "    #Takes 3 different size arrays of type numpy_array\n",
    "    #First array represent the positive examples while the others are negative examples\n",
    "    #Returns a dataset (X,y) where X is a combination of the 3 arrays and y is the lables\n",
    "    vector_size = len(positive_docs_svd[0])\n",
    "    ones_lables = np.ones(len(positive_docs_svd), dtype=np.int)\n",
    "    size_negative = len(negative_docs_svd) + len(negative_rand_docs_svd)\n",
    "    negative_examples = np.hstack((negative_docs_svd, negative_rand_docs_svd))\n",
    "    zeros_lables = np.zeros(len(negative_examples), dtype=np.int)\n",
    "    y = np.hstack((ones_lables, zeros_lables))\n",
    "    X_in = np.hstack((positive_docs_svd, negative_examples))\n",
    "    \n",
    "    X = np.zeros((len(X_in),vector_size))\n",
    "    for (i, x) in enumerate(X_in):\n",
    "        for (j, f) in enumerate(x):\n",
    "            X[i,j] = f\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 150)\n",
      "(804,)\n"
     ]
    }
   ],
   "source": [
    "#Process needs about 20 minutes on 32GB-RAM didicated machine with swapping memory of 90GB\n",
    "#We recommend a virtual machine with ~90GB-RAM instead or at least 64GB with swapping enabled\n",
    "classifier = RandomForestClassifier(n_estimators=500)\n",
    "X, y = generate_dataset(positive_docs_svd, negative_docs_svd, negative_rand_docs_svd)\n",
    "\n",
    "\n",
    "print X.shape\n",
    "print y.shape\n",
    "classifier.fit(X, y)\n",
    "sim_results = classifier.predict_proba(svd)\n",
    "\n",
    "pickle.dump(sim_results, open('results/activelearn_sim_results.pickle', 'wb'))\n",
    "pickle.dump(classifier, open('activelearn_clf.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4174940, 2)\n",
      "random example [ 0.882  0.118]\n",
      "positive example [ 0.038  0.962]\n",
      "negative example [ 0.812  0.188]\n"
     ]
    }
   ],
   "source": [
    "sim_results = pickle.load(open('results/activelearn_sim_results.pickle', 'rb'))\n",
    "print sim_results.shape\n",
    "print 'random example', sim_results[3405154]\n",
    "print 'positive example', sim_results[int(inversed_index[positive_ids[200]])]\n",
    "print 'negative example', sim_results[int(inversed_index[negative_ids[50]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96199999999999997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_results[:,1][int(inversed_index[positive_ids[200]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'ANNOTATED001MENTAL000ROTATION10100000162'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['181']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_results = pickle.load(open('results/activelearn_sim_results.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sorted_results(sim_results, doc_id_dict, count_positive):\n",
    "    results = dict()\n",
    "    for i, score in enumerate(sim_results[:,1][count_positive:]):\n",
    "        doc_id = doc_id_dict[str(count_positive + i)]\n",
    "        results[doc_id] = score\n",
    "    sorted_results = OrderedDict(sorted(results.items(), key=lambda k: k[1], reverse=True))\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4174758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sorted_results(sim_results, index, 182)\n",
    "print len(results)\n",
    "len(sim_results) - len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10k = pd.DataFrame(results.items()[:10000])\n",
    "top10k.to_csv('top10k_activelearn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4174559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_excluding_MRISTEX = sorted_results(sim_results, index, 381)\n",
    "print len(results_excluding_MRISTEX)\n",
    "len(sim_results) - len(results_excluding_MRISTEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results) - len(results_excluding_MRISTEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4174940"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim_results) - len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim_results) - len(results_excluding_MRISTEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10k_results_excluding_MRISTEX = pd.DataFrame(results_excluding_MRISTEX.items()[:10000])\n",
    "top10k_results_excluding_MRISTEX.to_csv('top10k_activelearn_excluding_MRISTEX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISTEX_7E34BEBFB13F51AEC21E8DBA16B56F69801FB6CD</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISTEX_0552C8637274B37867899F4D2783BCC00E438A6C</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISTEX_4CC2253534C9F032393A3971E6CC5E4AAD845A05</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISTEX_B18087285607420B2686431EDD704EAFD76D5F5B</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTEX_94B114260B0B11B0D8BBDDFBE4E186D0A14282DD</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISTEX_1A76D96B351A7BC76575D8B96C1A8A67655409BC</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISTEX_BFD567F907BD7F30E5FBE3886455092F3AD6AC73</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISTEX_D1FF7B2B1B79430FCD64F71DA33C0B275523E886</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ISTEX_218785326AB46691F45DA7216E0E1C97890FE019</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ISTEX_D964FD657961F0B54BDF142FB8D34C1C2E6C54C8</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0      1\n",
       "0  ISTEX_7E34BEBFB13F51AEC21E8DBA16B56F69801FB6CD  0.998\n",
       "1  ISTEX_0552C8637274B37867899F4D2783BCC00E438A6C  0.988\n",
       "2  ISTEX_4CC2253534C9F032393A3971E6CC5E4AAD845A05  0.988\n",
       "3  ISTEX_B18087285607420B2686431EDD704EAFD76D5F5B  0.986\n",
       "4  ISTEX_94B114260B0B11B0D8BBDDFBE4E186D0A14282DD  0.986\n",
       "5  ISTEX_1A76D96B351A7BC76575D8B96C1A8A67655409BC  0.984\n",
       "6  ISTEX_BFD567F907BD7F30E5FBE3886455092F3AD6AC73  0.984\n",
       "7  ISTEX_D1FF7B2B1B79430FCD64F71DA33C0B275523E886  0.980\n",
       "8  ISTEX_218785326AB46691F45DA7216E0E1C97890FE019  0.980\n",
       "9  ISTEX_D964FD657961F0B54BDF142FB8D34C1C2E6C54C8  0.980"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10k_results_excluding_MRISTEX[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'65F3E7E331C9C071195EE30ACEFFACA01F27D8CD', 0.96399999999999997)\n",
      "(u'02DFD687BB59004E10F87F8A1B8B29D8D1643DD9', 0.96399999999999997)\n",
      "(u'F25927D9CCB2A1DDC5045FA4388C33D090940C5D', 0.96399999999999997)\n",
      "(u'B9DDBDA6C785B111C56033CA730F956EE527CA02', 0.96199999999999997)\n",
      "(u'4A8A47F73791EA4109EBEC2CDDB8B2B8E6A44D38', 0.96199999999999997)\n",
      "(u'9F3A198CFC85E54C3644098D97BE85CB64A4F86E', 0.96199999999999997)\n",
      "(u'7116DEF8FC765D329BAA1C826D32803360D1217F', 0.96199999999999997)\n",
      "(u'401A0E69996285F9ACE0CD1A5AB73D25960F5959', 0.95999999999999996)\n",
      "(u'7ED5E3762DE21EEB9E9CC231447D6F32BBF9BBB3', 0.95999999999999996)\n",
      "(u'FCCE2ABACF816D7071126DF3D3500AB0F6BF156E', 0.95799999999999996)\n"
     ]
    }
   ],
   "source": [
    "for res_doc in results_excluding_MRISTEX.items()[:10]:\n",
    "    print res_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'7E34BEBFB13F51AEC21E8DBA16B56F69801FB6CD', 0.998)\n",
      "(u'F4CDE81D8D8F23F6507262F6574A6F6E85F2C82D', 0.99199999999999999)\n",
      "(u'0552C8637274B37867899F4D2783BCC00E438A6C', 0.98799999999999999)\n",
      "(u'4CC2253534C9F032393A3971E6CC5E4AAD845A05', 0.98799999999999999)\n",
      "(u'94B114260B0B11B0D8BBDDFBE4E186D0A14282DD', 0.98599999999999999)\n",
      "(u'B18087285607420B2686431EDD704EAFD76D5F5B', 0.98599999999999999)\n",
      "(u'1A76D96B351A7BC76575D8B96C1A8A67655409BC', 0.98399999999999999)\n",
      "(u'BFD567F907BD7F30E5FBE3886455092F3AD6AC73', 0.98399999999999999)\n",
      "(u'218785326AB46691F45DA7216E0E1C97890FE019', 0.97999999999999998)\n",
      "(u'D1FF7B2B1B79430FCD64F71DA33C0B275523E886', 0.97999999999999998)\n",
      "(u'D964FD657961F0B54BDF142FB8D34C1C2E6C54C8', 0.97999999999999998)\n",
      "(u'622C8F010109933F69BC38E537A1FFFFF307E9FA', 0.97799999999999998)\n"
     ]
    }
   ],
   "source": [
    "for (i, res_doc) in enumerate(results.items()):\n",
    "    print res_doc\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-715ba6437fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/activelearn_results.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(results, open('results/activelearn_results.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(results.items()[:10000], open('results/activelearn_top10k_results.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "top10k = df.from_csv('top10k_activelearn.csv')\n",
    "top_ids = [article.split('_')[1] for article in top10k['0']]\n",
    "mr_articles = json.load(open('sample_data/MentalRotationInMetaDataIstexWithoutAnnotated.json','r'))\n",
    "mr_ids = [doc['istex_id'] for doc in mr_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of results without \"mental rotation\" in meta data out of the top 10000 =  9620\n"
     ]
    }
   ],
   "source": [
    "top_wo_mr = []\n",
    "for top_id in top_ids:\n",
    "    if  top_id not in mr_ids:\n",
    "        top_wo_mr.append(top_id)\n",
    "print 'number of results without \"mental rotation\" in meta data out of the top 10000 = ',len(top_wo_mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top959 = pd.DataFrame(top_wo_mr[:959])\n",
    "top959.to_csv('top959_activelearn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10kwo = pd.DataFrame(top_wo_mr[:10000])\n",
    "top10kwo.to_csv('top10kwo_activelearn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
