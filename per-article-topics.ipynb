{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is design as a prototype for generating a ranked list of topics per article out of a ranked list of articles per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, pickle, argparse, json, os, urllib2\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_from(q, f):\n",
    "    q = q+'&from='+str(f)\n",
    "    response = urllib2.urlopen(q)\n",
    "    data = json.load(response)\n",
    "    subject_ids = np.array(range(len(data['hits'])), dtype=np.object)\n",
    "    for (i, hit) in enumerate(data['hits']):\n",
    "        subject_ids[i] = hit['id']\n",
    "    return subject_ids\n",
    "\n",
    "def query(q):\n",
    "    response = urllib2.urlopen(q)\n",
    "    data = json.load(response)\n",
    "    nb_requests = 1 + data['total'] / 1000\n",
    "    if nb_requests > 10: # maximum number of pages due to API pagination restrection\n",
    "        nb_requests = 10\n",
    "    subject_ids = query_from(q, 0)\n",
    "    for i in range(nb_requests)[1:]:\n",
    "        f = i * 1000\n",
    "        next_request = query_from(q, f)\n",
    "        subject_ids = np.hstack((subject_ids, next_request))\n",
    "    return subject_ids.tolist()\n",
    "\n",
    "def find_intersection(list_a, list_b):\n",
    "    return list(set(list_a) & set(list_b))\n",
    "\n",
    "def term2url(string):\n",
    "    string = string.split(' ')\n",
    "    res = '%22'\n",
    "    for s in string:\n",
    "        res = res + s + '%20'\n",
    "    res = res[:-3]\n",
    "    res = res + '%22'\n",
    "    return res\n",
    "\n",
    "def babel_synset(synset):\n",
    "    q = 'https://api.istex.fr/document/?q=(('\n",
    "    for syn in synset:\n",
    "        syn = term2url(syn)\n",
    "        q = q + 'title:' + syn + '%20OR%20abstract:' + syn + '%20OR%20'\n",
    "    q = q[:-8]\n",
    "    q = q + ')%20AND%20(qualityIndicators.abstractWordCount:[35%20500]%20AND%20qualityIndicators.pdfPageCount:[3%2060]%20AND%20publicationDate:[1990%202016]%20AND%20language:(%22eng%22%20OR%20%22unknown%22)%20AND%20genre:(%22research_article%22%20OR%20%22conference[eBooks]%22%20OR%20%22article%22%20)%20))&size=1000&output=id'\n",
    "    return q\n",
    "\n",
    "def babel_subj_keyword(topic):\n",
    "    q = 'https://api.istex.fr/document/?q=(('\n",
    "    topic = term2url(topic)\n",
    "    q = q+ 'subject.value:' + topic + '%20OR%20keywords:' + topic\n",
    "    q = q + ')%20AND%20(qualityIndicators.abstractWordCount:[35%20500]%20AND%20qualityIndicators.pdfPageCount:[3%2060]%20AND%20publicationDate:[1990%202016]%20AND%20language:(%22eng%22%20OR%20%22unknown%22)%20AND%20genre:(%22research_article%22%20OR%20%22conference[eBooks]%22%20OR%20%22article%22%20)%20))&size=1000&output=id'\n",
    "    return q\n",
    "\n",
    "def babel_title_abst(topic):\n",
    "    q = 'https://api.istex.fr/document/?q=(('\n",
    "    topic = term2url(topic)\n",
    "    q = q+ 'title:' + topic + '%20OR%20abstract:' + topic\n",
    "    q = q + ')%20AND%20(qualityIndicators.abstractWordCount:[35%20500]%20AND%20qualityIndicators.pdfPageCount:[3%2060]%20AND%20publicationDate:[1990%202016]%20AND%20language:(%22eng%22%20OR%20%22unknown%22)%20AND%20genre:(%22research_article%22%20OR%20%22conference[eBooks]%22%20OR%20%22article%22%20)%20))&size=1000&output=id'\n",
    "    return q\n",
    "\n",
    "def babelnet_syn_get_input(topic, synset):\n",
    "    results = query(babel_synset(synset))\n",
    "    _gs = query(babel_subj_keyword(topic))\n",
    "    results = find_intersection(results, inversed_index.keys())\n",
    "    _abst_title = query(babel_title_abst(topic))\n",
    "    test_set = _inter = {x for x in _gs if x not in _abst_title}\n",
    "    test_set = find_intersection(test_set, inversed_index.keys())\n",
    "    results = list(results)\n",
    "    test = list(test_set)\n",
    "    print 'initial_corpus size:', len(find_intersection(_abst_title, inversed_index.keys()))\n",
    "    return results, test\n",
    "\n",
    "def get_fusion_res(s3h_res_pickle, topic, synset):\n",
    "    topic_s3h_results = pickle.load(open(s3h_res_pickle,'rb'))\n",
    "    if type(topic_s3h_results) is OrderedDict:\n",
    "        topic_s3h_results = topic_s3h_results.items()\n",
    "    topic_s3h_top100k_results = topic_s3h_results[:100000]\n",
    "    babel_results, test = babelnet_syn_get_input(topic, synset)\n",
    "    fus = np.array(range(100000))\n",
    "    fus = fus * len(babel_results)\n",
    "    for i, s3h in enumerate(topic_s3h_top100k_results):\n",
    "        for j, bab in enumerate(babel_results):\n",
    "            if s3h[0] == bab:\n",
    "                fus[i] = (i + j) / 2\n",
    "    fusion_df = pd.DataFrame(data=topic_s3h_top100k_results, columns=[\"istex_id\", \"3sh_score\"])\n",
    "    fusion_df[\"fus_rank\"] = fus\n",
    "    fusion_res = fusion_df.sort_values(\"fus_rank\")\n",
    "    return fusion_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original inversed_index\n",
      "[(u'ISTEX_D89FA3AC3521074D46F4245762153DF497BFFA1F', 2002320), (u'ISTEX_18EAF4D6A126B077EB38667801D1B7292F32FF49', 2483732), (u'ISTEX_5F91044435FCC4FABB9F02E31467DCFE75F4A7BE', 1429049)]\n",
      "processed inversed_index\n",
      "[(u'FCF1393F9B8136AC08FB67E88F94F3CF62C17288', 3517138), (u'482E1102A1114327A744FD2ADB4D9F8FF7E9A70B', 751643), (u'A81022B6295AE66F68A10222C3B94A06B033C1BA', 3983232)]\n"
     ]
    }
   ],
   "source": [
    "#loading SDV of istex articles\n",
    "inv_index = json.load(open('../RecSys_Exp_files/182_381_vec150_results/output_paragraph_inversed_index.json','rb'))\n",
    "print 'original inversed_index'\n",
    "print inv_index.items()[:3]\n",
    "inversed_index = dict()\n",
    "for (k, v) in inv_index.items():\n",
    "    key = k.split('_')[1]\n",
    "    inversed_index[key] = v\n",
    "print 'processed inversed_index'\n",
    "print inversed_index.items()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_corpus size: 8160\n"
     ]
    }
   ],
   "source": [
    "bab = \"nursing, Nursing Science, Staff nurse, Adult nursing, Flightnurse, nurse, Nursing History, Nursing Officer, Nursing practice, Nursing skills, Nursing staff, Nursing Student, Nursing unit, Nurxing, Practice of nursing\"\n",
    "bab.replace('&', 'and')\n",
    "synset = bab.split(',')\n",
    "topic = 'Nursing'\n",
    "s3h_res_pickle = \"results/Nursing_results.pickle\"\n",
    "nursing_AE2TS = get_fusion_res(s3h_res_pickle, topic, synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>istex_id</th>\n",
       "      <th>3sh_score</th>\n",
       "      <th>fus_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>49630CDB3DC2ABEB1D9209F79CF6424C73171689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>C4E914079936089EF0B179AFF5A655E3BC2A068B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>39C8CDD40F50BE64D33FA53857280FDDD017E41A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>964D0413B5C20E25E268B2BA677B64E0E8EFB3FC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>D1F760638AB9537A33BB1177EB56B572E95B6663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     istex_id  3sh_score  fus_rank\n",
       "28   49630CDB3DC2ABEB1D9209F79CF6424C73171689        1.0        99\n",
       "165  C4E914079936089EF0B179AFF5A655E3BC2A068B        1.0       106\n",
       "233  39C8CDD40F50BE64D33FA53857280FDDD017E41A        1.0       127\n",
       "188  964D0413B5C20E25E268B2BA677B64E0E8EFB3FC        1.0       154\n",
       "220  D1F760638AB9537A33BB1177EB56B572E95B6663        1.0       169"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nursing_AE2TS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_corpus size: 8455\n"
     ]
    }
   ],
   "source": [
    "bab =\"surgery, operation, surgical operation, surgical procedure, surgical process, Chirurgery, Chirurgical, Chirurgy, Complications of surgery, Corrective surgery, Elliptical excision, Emergency Surgery, Post-operation, Post-operative, Specialties in surgery, Sterile drapes, surgeon, Surgeons, Surgeries, Surgery in general practice, Surgery operation, Surgery specialties, Surgical, Surgical excision, Surgical excision of malignant lesions, Surgical specialties, Surgical technique, Surgically\"\n",
    "bab.replace('&', 'and')\n",
    "synset = bab.split(',')\n",
    "topic = 'Surgery'\n",
    "s3h_res_pickle = \"results/res__Surgery\"\n",
    "Surgery_AE2TS = get_fusion_res(s3h_res_pickle, topic, synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surgery_lst = Surgery_AE2TS[\"istex_id\"].tolist()[:10000]\n",
    "nursing_lst = nursing_AE2TS[\"istex_id\"].tolist()[:10000]\n",
    "len(find_intersection(surgery_lst,nursing_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DF75946C62E39EEBCA5CA56A7FFD387985996824',\n",
       " u'DA240C2D5DB51ADEE11E610A354B15C00AF64017',\n",
       " u'E8D1746D0985822B8886156A3E3F540110772D65',\n",
       " u'DBBF3B93D3AE905C37E2CDFDABB55768EB4CE416']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_intersection(surgery_lst,nursing_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_corpus size: 8999\n"
     ]
    }
   ],
   "source": [
    "bab = \"organ transplant, transplant, transplantation, Organ transplantation, Medical Transplantation, Transplant Surgery, Black market organs, First transplant, First transplantation, Intestinal transplant, Live organ transplants, Mixed chimerism, Organ and Tissue Donor, Organ doner, Organ farming, Organ transplantation in different countries, Organ transplantation therapy, Organ transplants, Skin transplant, Tissue transplant, Transplant Tourism and Organ Trafficking, Transplantation medicine, Transplantation surgery, Transplantation therapy, Transplanted organs, Transplantology\"\n",
    "bab.replace('&', 'and')\n",
    "synset = bab.split(',')\n",
    "topic = 'Transplantation'\n",
    "s3h_res_pickle = \"results/res_Transplantation\"\n",
    "Transplantation_AE2TS = get_fusion_res(s3h_res_pickle, topic, synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transplantation_lst = Transplantation_AE2TS[\"istex_id\"].tolist()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "print len(find_intersection(transplantation_lst, surgery_lst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'0F7BAEDE8860CC6ADFB22D63051AD01434692BB4',\n",
       " u'A4D27148ACEF37BF3CD23175B04B589603F737F7',\n",
       " u'7D46620DB62AE8B1E3DB17655413321FAB422763',\n",
       " u'191CDEE0F7ABFB096A6E2727656F47FFFB4E6136',\n",
       " u'FF1770048446CCE47249FC070E6941A90ABCCE80',\n",
       " u'8A776E3C9AC913283F13E71CD78FB388A58827BA']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(find_intersection(nursing_lst, transplantation_lst))\n",
    "find_intersection(nursing_lst, transplantation_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
